{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import LongformerModel, LongformerTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "class LFEmbeddingModule(nn.Module):\n",
    "    def __init__(self, args, device):\n",
    "        super(LFEmbeddingModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        if 'longformer' in self.args['model']:\n",
    "            self.lf_model = LongformerModel.from_pretrained(self.args['model'], output_hidden_states=True, output_attentions=True).to(device)\n",
    "            self.lf_tokenizer = LongformerTokenizer.from_pretrained(self.args['model'])\n",
    "        else:\n",
    "            self.lf_model = BertModel.from_pretrained(self.args['model'], output_hidden_states=True, output_attentions=True).to(device)\n",
    "            self.lf_tokenizer = BertTokenizer.from_pretrained(self.args['model'])\n",
    "            \n",
    "    def get_embeddings(self, comments, titles, descriptions, transcripts, other_comments):\n",
    "        indexed_cs = []\n",
    "        indexed_tok = []\n",
    "        max_len_total = self.args['max_len']\n",
    "        max_len_title = self.args['title_token_count']\n",
    "        max_len_desc = self.args['desc_token_count']\n",
    "        max_len_trans = self.args['transcript_token_count']\n",
    "        max_len_other_comments = self.args['other_comments_token_count']\n",
    "        padding = 'max_length' if self.args['pad_metadata'] else False\n",
    "        for comment, title, desc, transcript, other_comment in zip(comments, titles, descriptions, transcripts, other_comments):\n",
    "\n",
    "            input_c = self.lf_tokenizer.encode_plus(comment, max_length=max_len_total, padding=False, truncation=True)\n",
    "            enc_c = input_c['input_ids']\n",
    "            tok_c = input_c['token_type_ids']\n",
    "            if self.args['add_title']:\n",
    "                input_t = self.lf_tokenizer.encode_plus(title, max_length=max_len_title, padding=padding, truncation=True)\n",
    "                enc_t = input_t['input_ids']\n",
    "                tok_t = input_t['token_type_ids']\n",
    "                enc_c.extend(enc_t[1:])\n",
    "                tok_c.extend(tok_t[1:])\n",
    "                \n",
    "            if self.args['add_description']:\n",
    "                input_d = self.lf_tokenizer.encode_plus(desc, max_length=max_len_desc, padding=padding, truncation=True)\n",
    "                enc_d = input_d['input_ids']\n",
    "                tok_d = input_d['token_type_ids']\n",
    "                enc_c.extend(enc_d[1:])\n",
    "                tok_c.extend(tok_d[1:])\n",
    "                \n",
    "            if self.args['add_transcription']:\n",
    "                input_tr = self.lf_tokenizer.encode_plus(transcript, max_length=max_len_trans, padding=padding, truncation=True)\n",
    "                enc_tr = input_tr['input_ids']\n",
    "                tok_tr = input_tr['token_type_ids']\n",
    "                enc_c.extend(enc_tr[1:])\n",
    "                tok_c.extend(tok_tr[1:])\n",
    "                \n",
    "            if self.args['add_other_comments']:\n",
    "                input_oc = self.lf_tokenizer.encode_plus(other_comment, max_length=max_len_other_comments, padding=padding, truncation=True)\n",
    "                enc_oc = input_oc['input_ids']\n",
    "                tok_oc = input_oc['token_type_ids']\n",
    "                enc_c.extend(enc_oc[1:])\n",
    "                tok_c.extend(tok_oc[1:])\n",
    "                \n",
    "            enc_c = enc_c[:max_len_total]\n",
    "            tok_c = tok_c[:max_len_total]\n",
    "            # enc_c.extend((max_len_total - len(enc_c))*[self.lf_tokenizer.pad_token_id])\n",
    "            # tok_c.extend((max_len_total - len(tok_c))*[0])\n",
    "            indexed_cs.append(enc_c)\n",
    "            indexed_tok.append(tok_c)\n",
    "        indexed_cs = torch.tensor(indexed_cs).to(self.device)\n",
    "        indexed_tok = torch.tensor(indexed_tok).to(self.device)\n",
    "        return indexed_cs, indexed_tok\n",
    "    \n",
    "class CommentModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(CommentModel, self).__init__()\n",
    "        self.args = args\n",
    "        if 'base' in self.args['model']:\n",
    "            self.fc_size = 768\n",
    "        else:\n",
    "            self.fc_size = 1024   \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, text_emb):\n",
    "        out = self.fc(text_emb)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'model': 'bert-large-cased',\n",
    "    'max_len': 512,\n",
    "    'add_title': True,\n",
    "    'title_token_count': 40,\n",
    "    'add_description': True,\n",
    "    'desc_token_count': 80,\n",
    "    'add_transcription': True,\n",
    "    'transcript_token_count': 200,\n",
    "    'add_other_comments': True,\n",
    "    'other_comments_token_count': 512,\n",
    "    'pad_metadata': False\n",
    "}\n",
    "device = torch.device('cpu')\n",
    "lf_model = LFEmbeddingModule(args, device)\n",
    "comment_model = CommentModel(args).to(device)\n",
    "criterion = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_weights(lf_model, comment_model, device):\n",
    "    lf_path = os.path.join('./11Jul2022_ethereal-blaze-26/lf_model_ethereal-blaze-26.pth.tar')\n",
    "    comment_path = os.path.join('./11Jul2022_ethereal-blaze-26/comment_model_ethereal-blaze-26.pth.tar')\n",
    "    lf_checkpoint = torch.load(lf_path, map_location=device)\n",
    "    comment_checkpoint = torch.load(comment_path, map_location=device)\n",
    "    lf_model.lf_model.load_state_dict(lf_checkpoint['state_dict'])\n",
    "    comment_model.load_state_dict(comment_checkpoint['state_dict'])\n",
    "    return lf_model, comment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_model, comment_model = load_weights(lf_model, comment_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_total=512\n",
    "comments = ['\"Minister Freeland\" = kyke controlling your bank account.']\n",
    "titles = [\"Canada tells people how they can get their bank accounts unfrozen if they donated to the Trucker c..\"]\n",
    "descriptions = [\"trucker convoy liberal shutdown anti vaccine bank accounts canada tells people movements look reacted agree unfrozen donated machine machine does antifa versus mandate protests http ones raging blm react does agree support liberal think look people versus donated trucker mandate does tells reacted tells people bank canada reacted blm antifa anti vaccine mandate protests shutdown raging machine machine protests http think ones accounts unfrozen look reacted blm support movements react anti shutdown liberal versus react anti support donated trucker convoy trucker donated agree support movements convoy mandate protests vaccine does agree convoy liberal think liberal think ones\"]\n",
    "transcripts = [\"banks emergencies act constituents donated according rcmp rcmp unfrozen stop blockade occupation person certain account frozen mistaken use powers turn minister freeland leaders organizers protests including small action vet connection swap behle avec 50 needs speak police people trucks institutions names mp stated illegal action given financial government going concerned information financial institutions unfreeze going donor including frozen participation way occupation way account conservative use person certain wondering case mistaken ll organization communicate police organization avec person needs 50 bank accounts turn names granted frozen illegal emergencies donated small connection according rcmp given financial participation illegal blockades concerned accounts wondering granted banks small amounts communicate financial institutions blockade swap institutions concerned accounts donors ll turn unfreeze freeland rcmp act person certain account stop emergencies act government frozen wondering case trucks occupations blockades way account unfrozen speak given unfreeze accounts participation illegal going powers granted government going donor accounts frozen participation person needs including small donors people connection occupation blockade leaders bank illegal action vet occupations case certain blockades information according behle avec person minister account protests unfrozen stop blockade stated constituents act government organizers mistaken use bank accounts frozen swap protests people trucks powers granted banks stated institutions unfreeze accounts occupation person certain including granted banks emergencies vet small donors ll bank accounts institutions concerned donors names leaders organizers police frozen participation illegal frozen illegal action occupations blockades information way account occupation blockade swap behle donated financial institutions names account frozen illegal minister freeland rcmp participation freeland needs donor including small conservative mp institutions unfreeze small donated small amounts stop blockade occupation frozen account unfrozen stop banks emergencies mistaken financial institutions concerned organization communicate financial person government mp stated constituents blockades organization ll turn minister action illegal amounts 50 bank communicate accounts frozen wondering institutions names leaders use powers donors ll police organization communicate amounts 50 vet connection occupation wondering case\"]\n",
    "other_comments = [\"\"]\n",
    "\n",
    "input_ids, token_type_ids = lf_model.get_embeddings(comments, titles, descriptions, transcripts, other_comments)\n",
    "attention = lf_model.lf_model(input_ids)[-1]\n",
    "# sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = lf_model.lf_tokenizer.convert_ids_to_tokens(input_id_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-b3222f6c0e0848b2b55c030e41dde000\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bertviz import head_view\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
