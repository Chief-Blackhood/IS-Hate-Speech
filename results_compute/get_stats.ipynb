{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPY_FILE_PATH = \"../npy_files/7Jun_vision\"\n",
    "\n",
    "filenames = os.listdir(path=NPY_FILE_PATH)\n",
    "filenames = sorted(filenames, key=lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames\n",
    "filenames = list(set([filename.split('_')[2] for filename in filenames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'test_labels_classic-voice-153.npy'\n",
    "labels_data = np.load(f'{NPY_FILE_PATH}/{filename}', allow_pickle=True)\n",
    "preds_data = np.load(f'{NPY_FILE_PATH}/{filename}', allow_pickle=True)\n",
    "\n",
    "\n",
    "print(labels_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The metrics for pleasant-deluge-145 run are:\n",
      "     Precision: 0.8516949152542372\n",
      "     Precision for (Non Hate): 0.635593220338983\n",
      "     Recall: 0.7003484320557491\n",
      "     Recall for (Non Hate): 0.8108108108108109\n",
      "     F1 score: 0.7686424474187381\n",
      "     F1 score for (Non Hate): 0.7125890736342043\n",
      "     Accuracy: 0.7436440677966102\n",
      "\n",
      "The metrics for faithful-cosmos-153 run are:\n",
      "     Precision: 0.8122605363984674\n",
      "     Precision for (Non Hate): 0.6445497630331753\n",
      "     Recall: 0.7386759581881533\n",
      "     Recall for (Non Hate): 0.7351351351351352\n",
      "     F1 score: 0.7737226277372263\n",
      "     F1 score for (Non Hate): 0.6868686868686869\n",
      "     Accuracy: 0.7372881355932204\n",
      "\n",
      "The metrics for lyric-cherry-147 run are:\n",
      "     Precision: 0.6982758620689655\n",
      "     Precision for (Non Hate): 0.6451612903225806\n",
      "     Recall: 0.8466898954703833\n",
      "     Recall for (Non Hate): 0.43243243243243246\n",
      "     F1 score: 0.7653543307086613\n",
      "     F1 score for (Non Hate): 0.5177993527508091\n",
      "     Accuracy: 0.684322033898305\n",
      "\n",
      "The metrics for jolly-bird-145 run are:\n",
      "     Precision: 0.8142857142857143\n",
      "     Precision for (Non Hate): 0.6927083333333334\n",
      "     Recall: 0.794425087108014\n",
      "     Recall for (Non Hate): 0.7189189189189189\n",
      "     F1 score: 0.8042328042328042\n",
      "     F1 score for (Non Hate): 0.7055702917771883\n",
      "     Accuracy: 0.7648305084745762\n",
      "\n",
      "The metrics for peach-violet-155 run are:\n",
      "     Precision: 0.7478260869565218\n",
      "     Precision for (Non Hate): 0.5247933884297521\n",
      "     Recall: 0.5993031358885017\n",
      "     Recall for (Non Hate): 0.6864864864864865\n",
      "     F1 score: 0.6653771760154739\n",
      "     F1 score for (Non Hate): 0.594847775175644\n",
      "     Accuracy: 0.6334745762711864\n",
      "\n",
      "The metrics for driven-silence-145 run are:\n",
      "     Precision: 0.7152777777777778\n",
      "     Precision for (Non Hate): 0.5597826086956522\n",
      "     Recall: 0.7177700348432056\n",
      "     Recall for (Non Hate): 0.5567567567567567\n",
      "     F1 score: 0.7165217391304348\n",
      "     F1 score for (Non Hate): 0.5582655826558266\n",
      "     Accuracy: 0.6546610169491526\n",
      "\n",
      "The metrics for classic-voice-153 run are:\n",
      "     Precision: 0.7979094076655052\n",
      "     Precision for (Non Hate): 0.6864864864864865\n",
      "     Recall: 0.7979094076655052\n",
      "     Recall for (Non Hate): 0.6864864864864865\n",
      "     F1 score: 0.7979094076655052\n",
      "     F1 score for (Non Hate): 0.6864864864864865\n",
      "     Accuracy: 0.7542372881355932\n",
      "\n",
      "The metrics for colorful-spaceship-152 run are:\n",
      "     Precision: 0.8969072164948454\n",
      "     Precision for (Non Hate): 0.5935251798561151\n",
      "     Recall: 0.6062717770034843\n",
      "     Recall for (Non Hate): 0.8918918918918919\n",
      "     F1 score: 0.7234927234927235\n",
      "     F1 score for (Non Hate): 0.7127429805615549\n",
      "     Accuracy: 0.7182203389830508\n",
      "\n",
      "The metrics for dashing-morning-143 run are:\n",
      "     Precision: 0.85\n",
      "     Precision for (Non Hate): 0.5698529411764706\n",
      "     Recall: 0.5923344947735192\n",
      "     Recall for (Non Hate): 0.8378378378378378\n",
      "     F1 score: 0.6981519507186857\n",
      "     F1 score for (Non Hate): 0.6783369803063458\n",
      "     Accuracy: 0.6885593220338984\n",
      "\n",
      "The metrics for confused-star-143 run are:\n",
      "     Precision: 0.7653429602888087\n",
      "     Precision for (Non Hate): 0.6153846153846154\n",
      "     Recall: 0.7386759581881533\n",
      "     Recall for (Non Hate): 0.6486486486486487\n",
      "     F1 score: 0.7517730496453902\n",
      "     F1 score for (Non Hate): 0.631578947368421\n",
      "     Accuracy: 0.7033898305084746\n",
      "\n",
      "The metrics for eager-durian-150 run are:\n",
      "     Precision: 0.8044871794871795\n",
      "     Precision for (Non Hate): 0.775\n",
      "     Recall: 0.8745644599303136\n",
      "     Recall for (Non Hate): 0.6702702702702703\n",
      "     F1 score: 0.8380634390651086\n",
      "     F1 score for (Non Hate): 0.7188405797101449\n",
      "     Accuracy: 0.7944915254237288\n",
      "\n",
      "The metrics for effortless-bee-149 run are:\n",
      "     Precision: 0.8604651162790697\n",
      "     Precision for (Non Hate): 0.5366666666666666\n",
      "     Recall: 0.5156794425087108\n",
      "     Recall for (Non Hate): 0.8702702702702703\n",
      "     F1 score: 0.644880174291939\n",
      "     F1 score for (Non Hate): 0.6639175257731958\n",
      "     Accuracy: 0.6546610169491526\n",
      "\n",
      "The metrics for radiant-morning-153 run are:\n",
      "     Precision: 0.8057851239669421\n",
      "     Precision for (Non Hate): 0.6\n",
      "     Recall: 0.6794425087108014\n",
      "     Recall for (Non Hate): 0.745945945945946\n",
      "     F1 score: 0.7372400756143667\n",
      "     F1 score for (Non Hate): 0.6650602409638555\n",
      "     Accuracy: 0.7055084745762712\n",
      "\n",
      "The metrics for swept-universe-150 run are:\n",
      "     Precision: 0.8339622641509434\n",
      "     Precision for (Non Hate): 0.6811594202898551\n",
      "     Recall: 0.7700348432055749\n",
      "     Recall for (Non Hate): 0.7621621621621621\n",
      "     F1 score: 0.8007246376811594\n",
      "     F1 score for (Non Hate): 0.7193877551020408\n",
      "     Accuracy: 0.7669491525423728\n",
      "\n",
      "The metrics for winter-plant-155 run are:\n",
      "     Precision: 0.821969696969697\n",
      "     Precision for (Non Hate): 0.6634615384615384\n",
      "     Recall: 0.7560975609756098\n",
      "     Recall for (Non Hate): 0.745945945945946\n",
      "     F1 score: 0.7876588021778586\n",
      "     F1 score for (Non Hate): 0.7022900763358779\n",
      "     Accuracy: 0.7521186440677966\n",
      "\n",
      "The metrics for spring-pond-142 run are:\n",
      "     Precision: 0.7191977077363897\n",
      "     Precision for (Non Hate): 0.7073170731707317\n",
      "     Recall: 0.8745644599303136\n",
      "     Recall for (Non Hate): 0.4702702702702703\n",
      "     F1 score: 0.7893081761006289\n",
      "     F1 score for (Non Hate): 0.564935064935065\n",
      "     Accuracy: 0.7161016949152542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in filenames:\n",
    "    run_name = filename.split('.')[0]\n",
    "    labels_data = np.load(f'{NPY_FILE_PATH}/test_labels_{filename}', allow_pickle=True)\n",
    "    preds_data = np.load(f'{NPY_FILE_PATH}/test_preds_{filename}', allow_pickle=True)\n",
    "    # else:\n",
    "    #     labels_data = np.load(f'{NPY_FILE_PATH}/{filenames[file_count+1]}', allow_pickle=True)\n",
    "    #     preds_data = np.load(f'{NPY_FILE_PATH}/{filenames[file_count]}', allow_pickle=True)\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for i in range(len(labels_data)):\n",
    "        for j in range(len(labels_data[i])):\n",
    "            labels.append(labels_data[i][j][-1])\n",
    "            preds.append(preds_data[i][j][-1])\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    preds[preds >= 0.5] = 1\n",
    "    preds[preds < 0.5] = 0\n",
    "    \n",
    "    # preds = 1/(1 + np.exp(-preds))\n",
    "    print(f\"\\nThe metrics for {run_name} run are:\")\n",
    "    print(\"     Precision:\", precision_score(labels, preds, pos_label=1))\n",
    "    print(\"     Precision for (Non Hate):\", precision_score(labels, preds, pos_label=0))\n",
    "    print(\"     Recall:\", recall_score(labels, preds, pos_label=1))\n",
    "    print(\"     Recall for (Non Hate):\", recall_score(labels, preds, pos_label=0))\n",
    "    print(\"     F1 score:\", f1_score(labels, preds, pos_label=1))\n",
    "    print(\"     F1 score for (Non Hate):\", f1_score(labels, preds, pos_label=0))\n",
    "    print(\"     Accuracy:\", accuracy_score(labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05653011053800583\n",
      "0.9987609386444092\n",
      "0.949430525302887\n",
      "0.9984368681907654\n",
      "0.9973963499069214\n",
      "0.6387729644775391\n",
      "0.19644924998283386\n",
      "0.23118489980697632\n",
      "0.9954143762588501\n",
      "0.9946818947792053\n",
      "0.9854972958564758\n",
      "0.487801194190979\n",
      "0.9666085839271545\n",
      "0.03705838695168495\n",
      "0.038530219346284866\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for batch in preds_data:\n",
    "    for el in batch:\n",
    "        print(el[-1])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
