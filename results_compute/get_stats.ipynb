{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPY_FILE_PATH = \"../npy_files/13Jun2023_without_multitask\"\n",
    "\n",
    "filenames = os.listdir(path=NPY_FILE_PATH)\n",
    "filenames = sorted(filenames, key=lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames\n",
    "filenames = list(set([filename.split('_')[2] for filename in filenames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fanciful-puddle-265.npy'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "filename = filenames[0]\n",
    "labels_data = np.load(f'{NPY_FILE_PATH}/test_labels_{filename}', allow_pickle=True)\n",
    "preds_data = np.load(f'{NPY_FILE_PATH}/test_preds_{filename}', allow_pickle=True)\n",
    "\n",
    "\n",
    "print(labels_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6832144260406494]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The metrics for fanciful-puddle-265 run are:\n",
      "     Precision: 0.8654708520179372\n",
      "     Precision for (Non Hate): 0.6224899598393574\n",
      "     Recall: 0.6724738675958188\n",
      "     Recall for (Non Hate): 0.8378378378378378\n",
      "     F1 score: 0.7568627450980391\n",
      "     F1 score for (Non Hate): 0.7142857142857142\n",
      "     Accuracy: 0.7372881355932204\n",
      "\n",
      "The metrics for twilight-snowflake-263 run are:\n",
      "     Precision: 0.7720588235294118\n",
      "     Precision for (Non Hate): 0.615\n",
      "     Recall: 0.7317073170731707\n",
      "     Recall for (Non Hate): 0.6648648648648648\n",
      "     F1 score: 0.7513416815742396\n",
      "     F1 score for (Non Hate): 0.638961038961039\n",
      "     Accuracy: 0.7055084745762712\n",
      "\n",
      "The metrics for driven-wildflower-253 run are:\n",
      "     Precision: 0.8352490421455939\n",
      "     Precision for (Non Hate): 0.6729857819905213\n",
      "     Recall: 0.759581881533101\n",
      "     Recall for (Non Hate): 0.7675675675675676\n",
      "     F1 score: 0.7956204379562045\n",
      "     F1 score for (Non Hate): 0.7171717171717171\n",
      "     Accuracy: 0.7627118644067796\n",
      "\n",
      "The metrics for ruby-firefly-262 run are:\n",
      "     Precision: 0.7916666666666666\n",
      "     Precision for (Non Hate): 0.6793478260869565\n",
      "     Recall: 0.794425087108014\n",
      "     Recall for (Non Hate): 0.6756756756756757\n",
      "     F1 score: 0.7930434782608695\n",
      "     F1 score for (Non Hate): 0.6775067750677507\n",
      "     Accuracy: 0.7478813559322034\n",
      "\n",
      "The metrics for morning-waterfall-256 run are:\n",
      "     Precision: 0.8072727272727273\n",
      "     Precision for (Non Hate): 0.6700507614213198\n",
      "     Recall: 0.7735191637630662\n",
      "     Recall for (Non Hate): 0.7135135135135136\n",
      "     F1 score: 0.7900355871886121\n",
      "     F1 score for (Non Hate): 0.6910994764397906\n",
      "     Accuracy: 0.75\n",
      "\n",
      "The metrics for olive-shape-262 run are:\n",
      "     Precision: 0.7656765676567657\n",
      "     Precision for (Non Hate): 0.6745562130177515\n",
      "     Recall: 0.8083623693379791\n",
      "     Recall for (Non Hate): 0.6162162162162163\n",
      "     F1 score: 0.7864406779661017\n",
      "     F1 score for (Non Hate): 0.6440677966101694\n",
      "     Accuracy: 0.7330508474576272\n",
      "\n",
      "The metrics for swift-haze-246 run are:\n",
      "     Precision: 0.6869300911854104\n",
      "     Precision for (Non Hate): 0.5734265734265734\n",
      "     Recall: 0.7874564459930313\n",
      "     Recall for (Non Hate): 0.44324324324324327\n",
      "     F1 score: 0.7337662337662337\n",
      "     F1 score for (Non Hate): 0.5\n",
      "     Accuracy: 0.652542372881356\n",
      "\n",
      "The metrics for toasty-disco-254 run are:\n",
      "     Precision: 0.7956204379562044\n",
      "     Precision for (Non Hate): 0.6515151515151515\n",
      "     Recall: 0.759581881533101\n",
      "     Recall for (Non Hate): 0.6972972972972973\n",
      "     F1 score: 0.7771836007130125\n",
      "     F1 score for (Non Hate): 0.6736292428198434\n",
      "     Accuracy: 0.7351694915254238\n",
      "\n",
      "The metrics for fresh-jazz-256 run are:\n",
      "     Precision: 0.7701149425287356\n",
      "     Precision for (Non Hate): 0.5924170616113744\n",
      "     Recall: 0.7003484320557491\n",
      "     Recall for (Non Hate): 0.6756756756756757\n",
      "     F1 score: 0.7335766423357662\n",
      "     F1 score for (Non Hate): 0.6313131313131313\n",
      "     Accuracy: 0.690677966101695\n",
      "\n",
      "The metrics for flowing-waterfall-256 run are:\n",
      "     Precision: 0.7785016286644951\n",
      "     Precision for (Non Hate): 0.7090909090909091\n",
      "     Recall: 0.8327526132404182\n",
      "     Recall for (Non Hate): 0.6324324324324324\n",
      "     F1 score: 0.8047138047138047\n",
      "     F1 score for (Non Hate): 0.6685714285714285\n",
      "     Accuracy: 0.7542372881355932\n",
      "\n",
      "The metrics for desert-star-249 run are:\n",
      "     Precision: 0.8008298755186722\n",
      "     Precision for (Non Hate): 0.5930735930735931\n",
      "     Recall: 0.6724738675958188\n",
      "     Recall for (Non Hate): 0.7405405405405405\n",
      "     F1 score: 0.7310606060606061\n",
      "     F1 score for (Non Hate): 0.6586538461538461\n",
      "     Accuracy: 0.6991525423728814\n",
      "\n",
      "The metrics for pious-puddle-249 run are:\n",
      "     Precision: 0.7445482866043613\n",
      "     Precision for (Non Hate): 0.6821192052980133\n",
      "     Recall: 0.8327526132404182\n",
      "     Recall for (Non Hate): 0.5567567567567567\n",
      "     F1 score: 0.7861842105263157\n",
      "     F1 score for (Non Hate): 0.6130952380952381\n",
      "     Accuracy: 0.7245762711864406\n",
      "\n",
      "The metrics for worthy-firefly-260 run are:\n",
      "     Precision: 0.8693693693693694\n",
      "     Precision for (Non Hate): 0.624\n",
      "     Recall: 0.6724738675958188\n",
      "     Recall for (Non Hate): 0.8432432432432433\n",
      "     F1 score: 0.7583497053045186\n",
      "     F1 score for (Non Hate): 0.7172413793103449\n",
      "     Accuracy: 0.739406779661017\n",
      "\n",
      "The metrics for radiant-night-265 run are:\n",
      "     Precision: 0.8617886178861789\n",
      "     Precision for (Non Hate): 0.668141592920354\n",
      "     Recall: 0.7386759581881533\n",
      "     Recall for (Non Hate): 0.8162162162162162\n",
      "     F1 score: 0.7954971857410881\n",
      "     F1 score for (Non Hate): 0.7347931873479318\n",
      "     Accuracy: 0.7690677966101694\n",
      "\n",
      "The metrics for fallen-yogurt-260 run are:\n",
      "     Precision: 0.6080508474576272\n",
      "     Precision for (Non Hate): 0.0\n",
      "     Recall: 1.0\n",
      "     Recall for (Non Hate): 0.0\n",
      "     F1 score: 0.7562582345191041\n",
      "     F1 score for (Non Hate): 0.0\n",
      "     Accuracy: 0.6080508474576272\n",
      "\n",
      "The metrics for pious-flower-245 run are:\n",
      "     Precision: 0.8297872340425532\n",
      "     Precision for (Non Hate): 0.7210526315789474\n",
      "     Recall: 0.8153310104529616\n",
      "     Recall for (Non Hate): 0.7405405405405405\n",
      "     F1 score: 0.8224956063268892\n",
      "     F1 score for (Non Hate): 0.7306666666666667\n",
      "     Accuracy: 0.7860169491525424\n",
      "\n",
      "The metrics for playful-jazz-265 run are:\n",
      "     Precision: 0.7540983606557377\n",
      "     Precision for (Non Hate): 0.5482456140350878\n",
      "     Recall: 0.6411149825783972\n",
      "     Recall for (Non Hate): 0.6756756756756757\n",
      "     F1 score: 0.6930320150659133\n",
      "     F1 score for (Non Hate): 0.6053268765133172\n",
      "     Accuracy: 0.6546610169491526\n",
      "\n",
      "The metrics for gallant-breeze-263 run are:\n",
      "     Precision: 0.7868852459016393\n",
      "     Precision for (Non Hate): 0.718562874251497\n",
      "     Recall: 0.8362369337979094\n",
      "     Recall for (Non Hate): 0.6486486486486487\n",
      "     F1 score: 0.8108108108108109\n",
      "     F1 score for (Non Hate): 0.6818181818181819\n",
      "     Accuracy: 0.7627118644067796\n",
      "\n",
      "The metrics for eager-tree-265 run are:\n",
      "     Precision: 0.7699386503067485\n",
      "     Precision for (Non Hate): 0.7534246575342466\n",
      "     Recall: 0.8745644599303136\n",
      "     Recall for (Non Hate): 0.5945945945945946\n",
      "     F1 score: 0.8189233278955955\n",
      "     F1 score for (Non Hate): 0.6646525679758308\n",
      "     Accuracy: 0.7648305084745762\n",
      "\n",
      "The metrics for charmed-durian-272 run are:\n",
      "     Precision: 0.8326693227091634\n",
      "     Precision for (Non Hate): 0.6470588235294118\n",
      "     Recall: 0.7282229965156795\n",
      "     Recall for (Non Hate): 0.772972972972973\n",
      "     F1 score: 0.7769516728624535\n",
      "     F1 score for (Non Hate): 0.7044334975369458\n",
      "     Accuracy: 0.7457627118644068\n",
      "\n",
      "The metrics for distinctive-wood-259 run are:\n",
      "     Precision: 0.7084548104956269\n",
      "     Precision for (Non Hate): 0.6589147286821705\n",
      "     Recall: 0.8466898954703833\n",
      "     Recall for (Non Hate): 0.4594594594594595\n",
      "     F1 score: 0.7714285714285716\n",
      "     F1 score for (Non Hate): 0.5414012738853503\n",
      "     Accuracy: 0.6949152542372882\n",
      "\n",
      "The metrics for expert-rain-246 run are:\n",
      "     Precision: 0.8271604938271605\n",
      "     Precision for (Non Hate): 0.6244541484716157\n",
      "     Recall: 0.7003484320557491\n",
      "     Recall for (Non Hate): 0.772972972972973\n",
      "     F1 score: 0.758490566037736\n",
      "     F1 score for (Non Hate): 0.6908212560386474\n",
      "     Accuracy: 0.7288135593220338\n",
      "\n",
      "The metrics for upbeat-shape-249 run are:\n",
      "     Precision: 0.7949790794979079\n",
      "     Precision for (Non Hate): 0.5836909871244635\n",
      "     Recall: 0.662020905923345\n",
      "     Recall for (Non Hate): 0.7351351351351352\n",
      "     F1 score: 0.7224334600760457\n",
      "     F1 score for (Non Hate): 0.6507177033492824\n",
      "     Accuracy: 0.690677966101695\n",
      "\n",
      "The metrics for devout-blaze-255 run are:\n",
      "     Precision: 0.9090909090909091\n",
      "     Precision for (Non Hate): 0.6311787072243346\n",
      "     Recall: 0.662020905923345\n",
      "     Recall for (Non Hate): 0.8972972972972973\n",
      "     F1 score: 0.7661290322580645\n",
      "     F1 score for (Non Hate): 0.7410714285714286\n",
      "     Accuracy: 0.7542372881355932\n",
      "\n",
      "The metrics for quiet-snowflake-265 run are:\n",
      "     Precision: 0.7285223367697594\n",
      "     Precision for (Non Hate): 0.585635359116022\n",
      "     Recall: 0.7386759581881533\n",
      "     Recall for (Non Hate): 0.572972972972973\n",
      "     F1 score: 0.7335640138408305\n",
      "     F1 score for (Non Hate): 0.5792349726775956\n",
      "     Accuracy: 0.673728813559322\n",
      "\n",
      "The metrics for easy-breeze-252 run are:\n",
      "     Precision: 0.8625954198473282\n",
      "     Precision for (Non Hate): 0.7095238095238096\n",
      "     Recall: 0.7874564459930313\n",
      "     Recall for (Non Hate): 0.8054054054054054\n",
      "     F1 score: 0.8233151183970856\n",
      "     F1 score for (Non Hate): 0.7544303797468355\n",
      "     Accuracy: 0.7944915254237288\n",
      "\n",
      "The metrics for vital-universe-262 run are:\n",
      "     Precision: 0.7206703910614525\n",
      "     Precision for (Non Hate): 0.7456140350877193\n",
      "     Recall: 0.8989547038327527\n",
      "     Recall for (Non Hate): 0.4594594594594595\n",
      "     F1 score: 0.8\n",
      "     F1 score for (Non Hate): 0.568561872909699\n",
      "     Accuracy: 0.7266949152542372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in filenames:\n",
    "    run_name = filename.split('.')[0]\n",
    "    labels_data = np.load(f'{NPY_FILE_PATH}/test_labels_{filename}', allow_pickle=True)\n",
    "    preds_data = np.load(f'{NPY_FILE_PATH}/test_preds_{filename}', allow_pickle=True)\n",
    "    # else:\n",
    "    #     labels_data = np.load(f'{NPY_FILE_PATH}/{filenames[file_count+1]}', allow_pickle=True)\n",
    "    #     preds_data = np.load(f'{NPY_FILE_PATH}/{filenames[file_count]}', allow_pickle=True)\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for i in range(len(labels_data)):\n",
    "        for j in range(len(labels_data[i][0])):\n",
    "            labels.append(labels_data[i][0][j][0])\n",
    "            preds.append(preds_data[i][0][j][0])\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    preds[preds >= 0.5] = 1\n",
    "    preds[preds < 0.5] = 0\n",
    "    \n",
    "    # preds = 1/(1 + np.exp(-preds))\n",
    "    print(f\"\\nThe metrics for {run_name} run are:\")\n",
    "    print(\"     Precision:\", precision_score(labels, preds, pos_label=1))\n",
    "    print(\"     Precision for (Non Hate):\", precision_score(labels, preds, pos_label=0))\n",
    "    print(\"     Recall:\", recall_score(labels, preds, pos_label=1))\n",
    "    print(\"     Recall for (Non Hate):\", recall_score(labels, preds, pos_label=0))\n",
    "    print(\"     F1 score:\", f1_score(labels, preds, pos_label=1))\n",
    "    print(\"     F1 score for (Non Hate):\", f1_score(labels, preds, pos_label=0))\n",
    "    print(\"     Accuracy:\", accuracy_score(labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05653011053800583\n",
      "0.9987609386444092\n",
      "0.949430525302887\n",
      "0.9984368681907654\n",
      "0.9973963499069214\n",
      "0.6387729644775391\n",
      "0.19644924998283386\n",
      "0.23118489980697632\n",
      "0.9954143762588501\n",
      "0.9946818947792053\n",
      "0.9854972958564758\n",
      "0.487801194190979\n",
      "0.9666085839271545\n",
      "0.03705838695168495\n",
      "0.038530219346284866\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for batch in preds_data:\n",
    "    for el in batch:\n",
    "        print(el[-1])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
