{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPY_FILE_PATH = \"../npy_files/13Jun_multilabel\"\n",
    "\n",
    "filenames = os.listdir(path=NPY_FILE_PATH)\n",
    "filenames = sorted(filenames, key=lambda x: x.split('_')[-1])\n",
    "filenames = list(set([filename.split('_')[2] for filename in filenames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    \n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worthy-field-274.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filenames[0]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_labels_data = np.load(f'{NPY_FILE_PATH}/eval_labels_{filename}', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_labels_data[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics for worthy-field-274 run are:\n",
      "(287, 4) (287, 4) (262, 4) (262, 4)\n",
      "Thresh: 0.0 \tHamming Loss: 0.43416030534351147 \tHamming Score: 0.3435114503816794\n",
      "Thresh: 0.1 \tHamming Loss: 0.41603053435114506 \tHamming Score: 0.33587786259541985\n",
      "Thresh: 0.2 \tHamming Loss: 0.39599236641221375 \tHamming Score: 0.3136132315521628\n",
      "Thresh: 0.30000000000000004 \tHamming Loss: 0.3797709923664122 \tHamming Score: 0.2862595419847328\n",
      "Thresh: 0.4 \tHamming Loss: 0.3597328244274809 \tHamming Score: 0.24681933842239187\n",
      "Thresh: 0.5 \tHamming Loss: 0.3101145038167939 \tHamming Score: 0.23091603053435114\n",
      "Thresh: 0.6000000000000001 \tHamming Loss: 0.29866412213740456 \tHamming Score: 0.1895674300254453\n",
      "Thresh: 0.7000000000000001 \tHamming Loss: 0.29961832061068705 \tHamming Score: 0.1628498727735369\n",
      "Thresh: 0.8 \tHamming Loss: 0.29866412213740456 \tHamming Score: 0.1450381679389313\n",
      "Thresh: 0.9 \tHamming Loss: 0.2967557251908397 \tHamming Score: 0.1342239185750636\n",
      "Thresh: 1.0 \tHamming Loss: 0.2948473282442748 \tHamming Score: 0.11323155216284986\n",
      "Thresh: 0 \tHamming Loss: 0.47909407665505227 \tHamming Score: 0.29036004645760743\n",
      "Organisation Precision: 0.14814814814814814 Recall: 0.375 F1 Score: 0.21238938053097345\n",
      "Location Precision: 0.2727272727272727 Recall: 0.1875 F1 Score: 0.2222222222222222\n",
      "Individual Precision: 0.5942028985507246 Recall: 0.2733333333333333 F1 Score: 0.3744292237442922\n",
      "Community Precision: 0.3 Recall: 0.09090909090909091 F1 Score: 0.13953488372093023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "        run_name = filename.split('.')[0]\n",
    "        print(f\"The metrics for {run_name} run are:\")\n",
    "        labels_data = np.load(f'{NPY_FILE_PATH}/test_labels_{filename}', allow_pickle=True)\n",
    "        preds_data = np.load(f'{NPY_FILE_PATH}/test_preds_{filename}', allow_pickle=True)\n",
    "        eval_labels_data = np.load(f'{NPY_FILE_PATH}/eval_labels_{filename}', allow_pickle=True)\n",
    "        eval_preds_data = np.load(f'{NPY_FILE_PATH}/eval_preds_{filename}', allow_pickle=True)\n",
    "        labels = []\n",
    "        preds = []\n",
    "        eval_labels = []\n",
    "        eval_preds = []\n",
    "        for i in range(len(labels_data)):\n",
    "                for j in range(len(labels_data[i][1])):\n",
    "                        labels.append(labels_data[i][1][j])\n",
    "                        preds.append(preds_data[i][1][j])\n",
    "        for i in range(len(eval_labels_data)):\n",
    "                for j in range(len(eval_labels_data[i][1])):\n",
    "                        eval_labels.append(eval_labels_data[i][1][j])\n",
    "                        eval_preds.append(eval_preds_data[i][1][j])\n",
    "        # for i in range(len(eval_labels_data)):\n",
    "        # for j in range(len(eval_labels_data[i])):\n",
    "        #         eval_labels.append(eval_labels_data[i][j][:5])\n",
    "        #         eval_preds.append(eval_preds_data[i][j][:5])\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        eval_labels = np.array(eval_labels)\n",
    "        eval_preds = np.array(eval_preds)\n",
    "        print(labels.shape, preds.shape, eval_labels.shape, eval_preds.shape)\n",
    "        max_hamming_score = 0\n",
    "        min_hamming_loss = 1\n",
    "        max_thres = 0\n",
    "        for thresh in np.linspace(0, 1, 11):\n",
    "                copy_preds = eval_preds.copy()\n",
    "                copy_preds[copy_preds >= thresh] = 1\n",
    "                copy_preds[copy_preds < thresh] = 0\n",
    "                print(\"Thresh:\", thresh, \"\\tHamming Loss:\", hamming_loss(copy_preds, eval_labels), \"\\tHamming Score:\", hamming_score(copy_preds, eval_labels))\n",
    "                if max_hamming_score > hamming_score(eval_labels, copy_preds):\n",
    "                        max_hamming_score = hamming_score(eval_labels, copy_preds)\n",
    "                        max_thres = thresh\n",
    "                        print(max_hamming_score)\n",
    "                        # min_hamming_loss = hamming_loss(eval_labels, copy_preds)\n",
    "        copy_preds = preds.copy()\n",
    "        copy_preds[copy_preds >= max_thres] = 1\n",
    "        copy_preds[copy_preds < max_thres] = 0                \n",
    "        \n",
    "        print(\"Thresh:\", max_thres, \"\\tHamming Loss:\", hamming_loss(copy_preds, labels), \"\\tHamming Score:\", hamming_score(copy_preds, labels))\n",
    "        preds[preds >= 0.5] = 1\n",
    "        preds[preds < 0.5] = 0\n",
    "        \n",
    "        mapping = {0: \"Organisation\", 1: \"Location\", 2: \"Individual\", 3: \"Community\", 4: \"None\"}\n",
    "        for i in range(0, 4):\n",
    "                print(f\"{mapping[i]} Precision: {precision_score(labels[:, i], preds[:, i])} Recall: {recall_score(labels[:, i], preds[:, i])} F1 Score: {f1_score(labels[:, i], preds[:, i])}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds >= 0.5] = 1\n",
    "preds[preds < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"Organisation\", 1: \"Location\", 2: \"Individual\", 3: \"Community\", 4: \"None\"}\n",
    "for i in range(0, 5):\n",
    "    print(f\"{mapping[i]} Precision: {precision_score(labels[:, i], preds[:, i])} Recall: {recall_score(labels[:, i], preds[:, i])} F1 Score: {f1_score(labels[:, i], preds[:, i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in range(len(preds)):\n",
    "    if (preds[i] != labels[i]).any():\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hate_towards_whom_aug/test.csv')\n",
    "df = df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[label for label in labels[idx].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = [\",\".join([mapping[i] for i, _pred in enumerate(pred) if _pred == 1]) for pred in preds[idx].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5613aab4ecbc566f677d86816432298c21e49c6be719c2e37efad0cf0ed1b4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
