{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import demoji"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sheet(url):\n",
    "    url_1 = url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "    data = pd.read_csv(url_1)\n",
    "    return data\n",
    "\n",
    "\n",
    "HATE_SHEET = \"https://docs.google.com/spreadsheets/d/16lxEwKVA_d_g5QRFNcBTyLz_OBPPB3wZdzZu2UnvLWQ/edit#gid=0\"\n",
    "POS_NON_HATE_SHEET = \"https://docs.google.com/spreadsheets/d/16lxEwKVA_d_g5QRFNcBTyLz_OBPPB3wZdzZu2UnvLWQ/edit#gid=1070451623\"\n",
    "NEU_NON_HATE_SHEET = \"https://docs.google.com/spreadsheets/d/16lxEwKVA_d_g5QRFNcBTyLz_OBPPB3wZdzZu2UnvLWQ/edit#gid=497253390\"\n",
    "\n",
    "hate_df = load_sheet(HATE_SHEET)\n",
    "pos_df = load_sheet(POS_NON_HATE_SHEET)\n",
    "neu_df = load_sheet(NEU_NON_HATE_SHEET)\n",
    "non_hate_df = pd.concat([pos_df, neu_df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_df.drop(\n",
    "    columns=[\n",
    "        \"Title\",\n",
    "        \"Is Video Hateful (Yes / No)\",\n",
    "        \"What Metadata / Information is Required?\",\n",
    "        \"Synthetic or Original?\",\n",
    "        \"Reviewer\",\n",
    "        \"Additional Verification Needed (Yes / No)\",\n",
    "        \"Reason For Additional Verficiation? (Only if YES)\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "hate_df.rename(\n",
    "    columns={\n",
    "        \"Link\": \"url\",\n",
    "        \"Video Category\": \"category\",\n",
    "        \"Comment\": \"comment\",\n",
    "        \"Hate Towards Whom?\": \"hate_towards_whom\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill columns for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_df[\"category\"] = hate_df[\"category\"].str.lower()\n",
    "hate_df[\"label\"] = \"yes\"\n",
    "hate_df.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for non hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hate_df.drop(\n",
    "    columns=[\n",
    "        \"Manual Inspection\",\n",
    "        \"Validator\",\n",
    "        \"scores\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "non_hate_df.rename(\n",
    "    columns={\n",
    "        \"type\": \"category\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "non_hate_df[\"category\"] = non_hate_df[\"category\"].str.lower()\n",
    "non_hate_df[\"hate_towards_whom\"] = \"None\"\n",
    "non_hate_df[\"label\"] = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([hate_df, non_hate_df])\n",
    "df.drop(columns=['Unnamed: 11'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data according to groups into test and train first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 453.04it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = df['url']\n",
    "\n",
    "best_state = 0\n",
    "min_diff = 1000000\n",
    "for random_state in tqdm(range(0, 10000)):\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=random_state)\n",
    "\n",
    "    for train_index, test_index in gss.split(df, groups=groups):\n",
    "        df_train = df.iloc[train_index]\n",
    "        df_test = df.iloc[test_index]\n",
    "\n",
    "    try:\n",
    "        count_train = df_train['category'].value_counts().to_dict()\n",
    "        count_test = df_test['category'].value_counts().to_dict()\n",
    "        diff = {k : count_train[k] - count_test[k] * 7 for k in count_train}\n",
    "        value_sum = sum(map(abs, diff.values()))\n",
    "        if value_sum < min_diff:\n",
    "            best_state = random_state\n",
    "            min_diff = value_sum\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8919 1705\n"
     ]
    }
   ],
   "source": [
    "print(best_state, min_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=best_state)\n",
    "\n",
    "for train_index, test_index in gss.split(df, groups=groups):\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_test = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 5), (472, 5))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../data/without_aug/train.csv\", index=False)\n",
    "df_test.to_csv(\"../data/without_aug/test.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all augmented data and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_orig = pd.read_csv(\"../data/without_aug/train.csv\")\n",
    "hate_aug = pd.read_csv(\"../data/with_aug/all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 5)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_orig.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make another split for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:17<00:00, 565.30it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = hate_orig['url']\n",
    "\n",
    "best_state = 0\n",
    "min_diff = 1000000\n",
    "for random_state in tqdm(range(0, 10000)):\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.35, random_state=random_state)\n",
    "\n",
    "    for train_index, test_index in gss.split(hate_orig, groups=groups):\n",
    "        hate_orig_train = hate_orig.iloc[train_index]\n",
    "        hate_orig_val = hate_orig.iloc[test_index]\n",
    "\n",
    "    try:\n",
    "        count_train = hate_orig_train['category'].value_counts().to_dict()\n",
    "        count_test = hate_orig_val['category'].value_counts().to_dict()\n",
    "        diff = {k : count_train[k] - count_test[k] * 6.5 for k in count_train}\n",
    "        value_sum = sum(map(abs, diff.values()))\n",
    "        if value_sum < min_diff:\n",
    "            best_state = random_state\n",
    "            min_diff = value_sum\n",
    "    except:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073 1521.0\n"
     ]
    }
   ],
   "source": [
    "print(best_state, min_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split eval and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.35, random_state=best_state)\n",
    "\n",
    "for train_index, test_index in gss.split(hate_orig, groups=groups):\n",
    "    hate_orig_train = hate_orig.iloc[train_index]\n",
    "    hate_orig_val = hate_orig.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1183, 5), (416, 5))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_orig_train.shape, hate_orig_val.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train aug data only from urls which are not in val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 121)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_in_val = list(set(hate_orig_val['url'].to_list()))\n",
    "urls_in_test = list(set(df_test['url'].to_list()))\n",
    "len(urls_in_val), len(urls_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4948, 5)\n",
      "(2866, 5)\n"
     ]
    }
   ],
   "source": [
    "print(hate_aug.shape)\n",
    "hate_aug = hate_aug[~hate_aug['url'].isin(urls_in_val)]\n",
    "hate_aug = hate_aug[~hate_aug['url'].isin(urls_in_test)]\n",
    "print(hate_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(text):\n",
    "    if text in ['Individual', 'Organisation', 'Location', 'Community', 'None']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = \",\".join([cat for cat in sorted(list(set(text.split()))) if check(cat)])\n",
    "    return text\n",
    "\n",
    "def process_text(text):\n",
    "    if text != text:\n",
    "        return ''\n",
    "    new_text = []\n",
    "\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        t = re.sub(r'http\\S+', '', t)\n",
    "        new_text.append(t)\n",
    "    new_text = \" \".join(new_text)\n",
    "    new_text = demoji.replace_with_desc(new_text, sep=' ')\n",
    "    new_text = re.sub('\\\\s+', ' ', new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, row in hate_orig_val.iterrows():\n",
    "    hate_orig_val.loc[id, 'comment'] = process_text(row['comment'])\n",
    "    hate_orig_val.loc[id, 'hate_towards_whom'] = clean(row['hate_towards_whom'])\n",
    "hate_orig_val.drop_duplicates(inplace=True)\n",
    "\n",
    "for id, row in hate_aug.iterrows():\n",
    "    hate_aug.loc[id, 'comment'] = process_text(row['comment'])\n",
    "    hate_aug.loc[id, 'hate_towards_whom'] = clean(row['hate_towards_whom'])\n",
    "hate_aug.drop_duplicates(inplace=True)\n",
    "\n",
    "for id, row in df_test.iterrows():\n",
    "    df_test.loc[id, 'comment'] = process_text(row['comment'])\n",
    "    df_test.loc[id, 'hate_towards_whom'] = clean(row['hate_towards_whom'])\n",
    "df_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_orig_val.to_csv('../data/with_aug_ttv/eval.csv', index=False)\n",
    "hate_aug.to_csv('../data/with_aug_ttv/train.csv', index=False)\n",
    "df_test.to_csv(\"../data/with_aug_ttv/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_towards_whom</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.bitchute.com/video/UNB7iw1M7Uco/</td>\n",
       "      <td>fashion &amp; beauty</td>\n",
       "      <td>you cannot mix Wild Chimps into the general po...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.bitchute.com/video/UNB7iw1M7Uco/</td>\n",
       "      <td>fashion &amp; beauty</td>\n",
       "      <td>there is no way to mix wild chimps with the ge...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.bitchute.com/video/UNB7iw1M7Uco/</td>\n",
       "      <td>fashion &amp; beauty</td>\n",
       "      <td>there's no way to mix wild chimps with the gen...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.bitchute.com/video/UNB7iw1M7Uco/</td>\n",
       "      <td>fashion &amp; beauty</td>\n",
       "      <td>you can't mix wild chimps with the general pop...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.bitchute.com/video/UNB7iw1M7Uco/</td>\n",
       "      <td>fashion &amp; beauty</td>\n",
       "      <td>keep white and black separate</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url          category  \\\n",
       "10  https://www.bitchute.com/video/UNB7iw1M7Uco/  fashion & beauty   \n",
       "11  https://www.bitchute.com/video/UNB7iw1M7Uco/  fashion & beauty   \n",
       "12  https://www.bitchute.com/video/UNB7iw1M7Uco/  fashion & beauty   \n",
       "13  https://www.bitchute.com/video/UNB7iw1M7Uco/  fashion & beauty   \n",
       "14  https://www.bitchute.com/video/UNB7iw1M7Uco/  fashion & beauty   \n",
       "\n",
       "                                              comment hate_towards_whom label  \n",
       "10  you cannot mix Wild Chimps into the general po...         Community   yes  \n",
       "11  there is no way to mix wild chimps with the ge...         Community   yes  \n",
       "12  there's no way to mix wild chimps with the gen...         Community   yes  \n",
       "13  you can't mix wild chimps with the general pop...         Community   yes  \n",
       "14                      keep white and black separate         Community   yes  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all augmented data and clean hate towards whom label for training, validation and test data (Different task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/with_aug/test_aug.csv')\n",
    "train_df = pd.read_csv('../data/with_aug/train_aug.csv')\n",
    "all_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_label = ''\n",
    "for id, row in train_df.iterrows():\n",
    "    if str(row['hate_towards_whom']) == 'nan':\n",
    "        train_df.iloc[id]['hate_towards_whom'] = prev_label\n",
    "    else:\n",
    "        prev_label = row['hate_towards_whom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None                       2354\n",
      "Individual                 1205\n",
      "Community                   827\n",
      "Location                    201\n",
      "Organisation                157\n",
      "Community,Individual         81\n",
      "Community,Location           47\n",
      "Community,Organisation       41\n",
      "Individual,Organisation      17\n",
      "Location,Organisation         9\n",
      "Individual,Location           9\n",
      "Name: hate_towards_whom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_df['hate_towards_whom'] = all_df['hate_towards_whom'].apply(lambda x: clean(x))\n",
    "all_df['comment'] = all_df['comment'].apply(lambda x: process_text(x))\n",
    "all_df.drop_duplicates(inplace=True)\n",
    "\n",
    "all_df.to_csv('../data/with_aug/all.csv', index=False)\n",
    "print(all_df['hate_towards_whom'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_towards_whom</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>because they are bad at geography. And if they...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens come from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens came from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens come from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0:50 that bozzo is wearing a US TShirt as well...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1:20 thats the future generation, look at his ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>That last white dude was seriously smoking som...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something ser...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something ser...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something really</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>the last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>this last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white man was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>God save the US. I'll pray for y'all from Indi...</td>\n",
       "      <td>Community,Location</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Well the map looks a hippopotamus in upsidedow...</td>\n",
       "      <td>Location</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url       category  \\\n",
       "851  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "852  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "853  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "854  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "855  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "857  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "858  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "859  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "860  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "861  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "862  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "863  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "864  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "865  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "866  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "867  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "869  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "\n",
       "                                               comment   hate_towards_whom  \\\n",
       "851  because they are bad at geography. And if they...           Community   \n",
       "852  if they don't know where the aliens come from ...           Community   \n",
       "853  if they don't know where the aliens came from ...           Community   \n",
       "854  if they don't know where the aliens come from ...           Community   \n",
       "855  0:50 that bozzo is wearing a US TShirt as well...          Individual   \n",
       "857  1:20 thats the future generation, look at his ...           Community   \n",
       "858  That last white dude was seriously smoking som...           Community   \n",
       "859  that last white dude was smoking something ser...           Community   \n",
       "860  that last white dude was smoking something ser...           Community   \n",
       "861  that last white dude was smoking something really           Community   \n",
       "862           the last white guy was smoking something           Community   \n",
       "863          this last white guy was smoking something           Community   \n",
       "864          that last white man was smoking something           Community   \n",
       "865          that last white guy was smoking something           Community   \n",
       "866         that last white dude was smoking something           Community   \n",
       "867  God save the US. I'll pray for y'all from Indi...  Community,Location   \n",
       "869  Well the map looks a hippopotamus in upsidedow...            Location   \n",
       "\n",
       "    label  \n",
       "851   yes  \n",
       "852   yes  \n",
       "853   yes  \n",
       "854   yes  \n",
       "855   yes  \n",
       "857   yes  \n",
       "858   yes  \n",
       "859   yes  \n",
       "860   yes  \n",
       "861   yes  \n",
       "862   yes  \n",
       "863   yes  \n",
       "864   yes  \n",
       "865   yes  \n",
       "866   yes  \n",
       "867   yes  \n",
       "869   yes  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[all_df['url'] == 'https://www.youtube.com/watch?v=QFOpN957p3s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_towards_whom</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>because they are bad at geography. And if they...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens come from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens came from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>if they don't know where the aliens come from ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0:50 that bozzo is wearing a US TShirt as well...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1:20 thats the future generation, look at his ...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>That last white dude was seriously smoking som...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something ser...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something ser...</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something really</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>the last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>this last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white man was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white guy was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>that last white dude was smoking something</td>\n",
       "      <td>Community</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>God save the US. I'll pray for y'all from Indi...</td>\n",
       "      <td>Community,Location</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>https://www.youtube.com/watch?v=QFOpN957p3s</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Well the map looks a hippopotamus in upsidedow...</td>\n",
       "      <td>Location</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url       category  \\\n",
       "750  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "751  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "752  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "753  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "754  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "755  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "756  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "757  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "758  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "759  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "760  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "761  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "762  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "763  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "764  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "765  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "766  https://www.youtube.com/watch?v=QFOpN957p3s  entertainment   \n",
       "\n",
       "                                               comment   hate_towards_whom  \\\n",
       "750  because they are bad at geography. And if they...           Community   \n",
       "751  if they don't know where the aliens come from ...           Community   \n",
       "752  if they don't know where the aliens came from ...           Community   \n",
       "753  if they don't know where the aliens come from ...           Community   \n",
       "754  0:50 that bozzo is wearing a US TShirt as well...          Individual   \n",
       "755  1:20 thats the future generation, look at his ...           Community   \n",
       "756  That last white dude was seriously smoking som...           Community   \n",
       "757  that last white dude was smoking something ser...           Community   \n",
       "758  that last white dude was smoking something ser...           Community   \n",
       "759  that last white dude was smoking something really           Community   \n",
       "760           the last white guy was smoking something           Community   \n",
       "761          this last white guy was smoking something           Community   \n",
       "762          that last white man was smoking something           Community   \n",
       "763          that last white guy was smoking something           Community   \n",
       "764         that last white dude was smoking something           Community   \n",
       "765  God save the US. I'll pray for y'all from Indi...  Community,Location   \n",
       "766  Well the map looks a hippopotamus in upsidedow...            Location   \n",
       "\n",
       "    label  \n",
       "750   yes  \n",
       "751   yes  \n",
       "752   yes  \n",
       "753   yes  \n",
       "754   yes  \n",
       "755   yes  \n",
       "756   yes  \n",
       "757   yes  \n",
       "758   yes  \n",
       "759   yes  \n",
       "760   yes  \n",
       "761   yes  \n",
       "762   yes  \n",
       "763   yes  \n",
       "764   yes  \n",
       "765   yes  \n",
       "766   yes  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_aug[hate_aug['url'] == 'https://www.youtube.com/watch?v=QFOpN957p3s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
